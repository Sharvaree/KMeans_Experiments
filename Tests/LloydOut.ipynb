{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Noise'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-95a53675ec30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mNoise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0madd_random_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_phi_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_random_noise_th\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mKMeansOut\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkmeansOutliers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mKmeansPPcenters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKMeanPlusPlus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Noise'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import random\n",
    "import numba\n",
    "import time\n",
    "from Noise import add_random_noise, compute_phi_star, cost, add_random_noise_th\n",
    "from KMeansOut import kmeansOutliers, cost\n",
    "from KmeansPPcenters import KMeanPlusPlus\n",
    "\n",
    "\n",
    "def get_csv(fileName):\n",
    "    return np.genfromtxt(fileName, delimiter=',')\n",
    "\n",
    "def random_centers(data, num_clusters):\n",
    "    centers= data[np.random.choice(np.arange(len(data)-1), num_clusters)]\n",
    "    return centers\n",
    "\n",
    "def  KPP_centers(data, num_clusters):\n",
    "    random_indx= random.randint(0, len(data)-1)\n",
    "    init=data[random_indx]\n",
    "    KPP=KMeanPlusPlus(num_clusters=num_clusters, init=init)\n",
    "    KPP.fit(data)\n",
    "    KPP_centers= KPP.centers\n",
    "    return KPP_centers\n",
    "\n",
    "def LloydOut(data, centers, num_clusters,z, min_value, max_value, tol, itr):\n",
    "    data_with_outliers, z_indx = add_random_noise_th(data, z, min_value, max_value)\n",
    "    data_inliers= np.delete(data, z_indx, axis=0)\n",
    "    \n",
    "    dist= distance.cdist(data_with_outliers, centers)\n",
    "    dist = np.amin(dist, axis = 1)                \n",
    "    X, d= data.shape\n",
    "    new_centers=np.zeros((num_clusters,d))\n",
    "    for i in range(itr):\n",
    "        dist= distance.cdist(data_with_outliers, np.array(centers))\n",
    "        cid = np.argmin(dist, axis=1)\n",
    "        dist = np.amin(dist, axis = 1)\n",
    "        \n",
    "        indx_list = np.argpartition(dist, -z)[-z:]\n",
    "        data_new = np.delete(data, indx_list, axis=0)\n",
    "        \n",
    "        dist_new = distance.cdist(data_new, centers)\n",
    "        cid = np.argmin(dist_new, axis=1)\n",
    "        dist_new = np.amin(dist_new, axis = 1)\n",
    "    \n",
    "        for j in range(num_clusters):\n",
    "            if len(data_new[cid==j])>0:\n",
    "                new_centers[j]= np.mean(data_new[cid==j], axis=0)\n",
    "    \n",
    "        #plt.figure()\n",
    "        #plt.scatter(data_new[:,0], data_new[:,1], c=cid)\n",
    "        #plt.scatter(centers[:,0], centers[:,1], marker='o', color= 'red')\n",
    "        #plt.scatter(new_centers[:,0], new_centers[:,1], marker='o', color= 'black')\n",
    "\n",
    "\n",
    "        old_centers= centers\n",
    "        centers=new_centers\n",
    "            \n",
    "        isOPTIMAL= True\n",
    "\n",
    "        if (len(np.setdiff1d(new_centers,old_centers)))>tol:\n",
    "            isOPTIMAL= False\n",
    "\n",
    "           \n",
    "        if isOPTIMAL:\n",
    "            break\n",
    "    #Step 10: Compute precision and recall\n",
    "    precision = len(np.intersect1d(z_indx, indx_list))/len(z_indx)\n",
    "    recall = len(np.intersect1d(z_indx, indx_list))/len(indx_list)\n",
    "    #x1= KPP.predict(data_with_outliers)\n",
    "    print((\"Precision:{}, recall:{}\". format(precision, recall)))\n",
    "    return new_centers, cid\n",
    "\n",
    "    \n",
    "def LO_cost(data, cid, centers, z):\n",
    "    dist= distance.cdist(data, np.array(centers))\n",
    "    dist = np.amin(dist, axis = 1)\n",
    "    indx_list = np.argpartition(dist, -z)[-z:] #get index of farthest z points\n",
    "    \n",
    "    cid_pruned = cid.copy()\n",
    "    cid_pruned[indx_list] = len(centers) + 1 # comment this line out if you do not want to remove points\n",
    "\n",
    "    cost= np.zeros(len(centers))\n",
    "    for i in range(len(centers)):\n",
    "        cluster_indx = np.where(cid_pruned==i)\n",
    "        cluster_points = data[cluster_indx]\n",
    "        cost[i] = np.sum((cluster_points-centers[i])**2)\n",
    "    total_cost= np.sum(cost)/len(data_new)\n",
    "        \n",
    "    return total_cost, indx_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
